{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.utils.extmath as sm\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import eig\n",
    "from numpy import dot, diag\n",
    "from scipy.linalg import sqrtm\n",
    "from scipy.spatial.distance import euclidean\n",
    "import random, math\n",
    "np.random.seed(42)\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Matrix Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_diag(M, a):\n",
    "    \"\"\"\n",
    "    M: square matrix\n",
    "    a: array of length number of rows\n",
    "    ----\n",
    "    fill the diagonal of M with values of array a\n",
    "    \"\"\"\n",
    "    s = M.shape\n",
    "    D = np.zeros(s)\n",
    "    for i in range(s[0]):\n",
    "        D[i,i] = a[i]\n",
    "    return D\n",
    "\n",
    "def rbf_kernel(X, sigma=1):\n",
    "    K = np.zeros((len(X), len(X)))\n",
    "    for a in range(len(X)):\n",
    "        for b in range(len(X)):\n",
    "            K[a, b] = rbf_function(X[a], X[b],sigma)\n",
    "    return K\n",
    "            \n",
    "def rbf_function(x, y, sigma=1):\n",
    "    exponent = - (euclidean(x, y) ** 2) / (2 * (sigma ** 2))\n",
    "    return np.exp(exponent)\n",
    "\n",
    "\n",
    "def diagonal_row_sum_matrix(M):\n",
    "    rows_sum = M.sum(axis = 1)\n",
    "    return fill_diag(M,rows_sum)\n",
    "\n",
    "def computeL(D,K):\n",
    "    Dinv = inv(D)\n",
    "    return sqrtm(Dinv).dot(K).dot(sqrtm(Dinv))\n",
    "\n",
    "def pick_eigs(eigen_vals, eigen_vect, k):\n",
    "    if k > len(eigen_vals):\n",
    "        k = len(eigen_vals)\n",
    "    eig_vals = list(eigen_vals)\n",
    "    new_eigs = []\n",
    "    new_eigen_vector = []\n",
    "    last_max_value = 0\n",
    "    for i in range(0, k):\n",
    "        argmax = eig_vals.index(max(eig_vals))\n",
    "        new_eigen_vector.append(eigen_vect[argmax])\n",
    "        new_eig = eig_vals.pop(argmax)\n",
    "        new_eigs.append(new_eig)\n",
    "        last_max_value = new_eig\n",
    "        \n",
    "    argmax = eig_vals.index(max(eig_vals))\n",
    "    new_eig = eig_vals[argmax]\n",
    "        \n",
    "    while(new_eig == last_max_value):\n",
    "        argmax = eig_vals.index(max(eig_vals))\n",
    "        new_eigen_vector.append(eigen_vect[argmax])\n",
    "        new_eig = eig_vals.pop(argmax)\n",
    "        new_eigs.append(new_eig)\n",
    "        \n",
    "    return np.array(new_eigs), np.array(new_eigen_vector)      \n",
    "    \n",
    "\n",
    "def build_K(lambdaCut, transfer, X, n_clusters, sigma=5):\n",
    "    \n",
    "    #Step 1 - K matrix\n",
    "    K = rbf_kernel(X, sigma)\n",
    "    D = diagonal_row_sum_matrix(K)\n",
    "    \n",
    "    #Step 2 - L matrix\n",
    "    L = computeL(D, K)\n",
    "    eigen_vals, U = eig(L)\n",
    "    eigen_vals, U = pick_eigs(eigen_vals, U, n_clusters)   \n",
    "    \n",
    "    Q = diag(eigen_vals)\n",
    "    \n",
    "    #Step 3 - Transfer Function\n",
    "    #choosing lambdacut\n",
    "    newEigen = transfer(eigen_vals, lambdaCut)\n",
    "    newEigen = diag(newEigen)\n",
    "    \n",
    "    #Step 4 - New Kernel matrix\n",
    "#     print(U.shape)26\n",
    "#     print(newEigen.shape)22   6222 62 26\n",
    "    newL = (U.T).dot(newEigen).dot((U))\n",
    "    newD = inv(diag(diag(L)))\n",
    "    newK = sqrtm(newD).dot(newL).dot(sqrtm(newD))\n",
    "    return newK\n",
    "    \n",
    "\n",
    "#TRANSFER FUNCTION\n",
    "def linear(vals, lambdaCut):\n",
    "    return vals\n",
    "\n",
    "def step(vals,lambdaCut):\n",
    "    return [ 1 if x >= lambdaCut else 0 for x in vals ]\n",
    "\n",
    "def linear_step(vals, lambdaCut):\n",
    "    return [ x if x >= lambdaCut else 0 for x in vals ]\n",
    "\n",
    "def polynomial(vals, exponent):\n",
    "    return [ np.power(x, exponent) for x in vals ]\n",
    "\n",
    "def polystep(vals, lambdaCut):\n",
    "    return [ np.power(x, 2) if x > lambdaCut else np.power(x, 2) for x in vals ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.78517596 0.19967378 0.51423444 0.59241457]\n",
      " [0.04645041 0.60754485 0.17052412 0.06505159]\n",
      " [0.94888554 0.96563203 0.80839735 0.30461377]\n",
      " [0.09767211 0.68423303 0.44015249 0.12203823]\n",
      " [0.49517691 0.03438852 0.9093204  0.25877998]\n",
      " [0.66252228 0.31171108 0.52006802 0.54671028]]\n",
      "[[ 0.99772467 -0.90724979 -0.56719876  1.18768366 -1.51683295 -0.31833761]\n",
      " [-0.90724979  0.82497928  0.51576449 -1.07998307  1.3792847   0.28947037]\n",
      " [-0.56719876  0.51576449  0.32244811 -0.67518898  0.86230781  0.18097247]\n",
      " [ 1.18768366 -1.07998307 -0.67518898  1.41380937 -1.80562611 -0.37894661]\n",
      " [-1.51683295  1.3792847   0.86230781 -1.80562611  2.30602918  0.48396616]\n",
      " [-0.31833761  0.28947037  0.18097247 -0.37894661  0.48396616  0.10156994]]\n"
     ]
    }
   ],
   "source": [
    "#dummy example\n",
    "nb_samples = 6 #nb of samples\n",
    "dim_sample = 4\n",
    "X = np.random.rand(nb_samples,dim_sample)\n",
    "print(X)\n",
    "lambdaCut = 1\n",
    "K = build_K(lambdaCut, linear, X, 2)\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Classification Test\n",
    "with open(\"../Dataset/textDataset.pickle\", \"rb\") as fp:\n",
    "    text = pickle.load(fp, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "labels = []\n",
    "for s in text:\n",
    "    instance = s[0].toarray()\n",
    "    vectors.append(instance[0])\n",
    "    labels.append(s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "963\n",
      "988\n"
     ]
    }
   ],
   "source": [
    "# Dividing in the 2 classes\n",
    "X1 = []\n",
    "label_X1 = []\n",
    "X2 = []\n",
    "label_X2 = []\n",
    "for i in range(0, len(labels)):\n",
    "    if labels[i] == 0:\n",
    "        X1.append(vectors[i])\n",
    "        label_X1.append(labels[i])\n",
    "    else:\n",
    "        X2.append(vectors[i])\n",
    "        label_X2.append(labels[i])\n",
    "length_X1 = len(label_X1)\n",
    "length_X2 = len(label_X2)\n",
    "\n",
    "print(length_X1)\n",
    "print(length_X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with K matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdaCut_or_polyDegree = 5\n",
    "K = build_K(lambdaCut_or_polyDegree, polynomial, vectors, 2, sigma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5064069707842133\n",
      "0.5079446437724244\n",
      "0.5033316248077909\n",
      "0.5053818554587391\n",
      "0.5064069707842133\n",
      "0.4935930292157868\n",
      "0.4935930292157868\n",
      "0.49410558687852385\n",
      "0.4925679138903127\n",
      "0.5007688364941056\n",
      "Mean of acc:  0.5007688364941056\n"
     ]
    }
   ],
   "source": [
    "acc = {}\n",
    "test_indexes = list(range(length_labels))\n",
    "testX = K[np.ix_(test_indexes, train_indexes)]\n",
    "testY = labels.copy()\n",
    "n_labeled = 16\n",
    "length_labels = len(labels)\n",
    "length_labeled_over_2 = n_labeled//2\n",
    "for i in range(0,10):\n",
    "    #select training data\n",
    "    trainingX=[]\n",
    "    trainingY=[]\n",
    "    train_indexes = []\n",
    "    counter = 0\n",
    "    #add n_labeled//2 points from class1\n",
    "    while counter < length_labeled_over_2:\n",
    "        index = random.randint(0,length_labels-1)\n",
    "        label = labels[index]\n",
    "        if label == 0:\n",
    "            train_indexes.append(index)\n",
    "            trainingY.append(label)\n",
    "            counter+=1\n",
    "    #add n_labeled//2 points from class2\n",
    "    counter = 0\n",
    "    while counter < length_labeled_over_2:\n",
    "        index = random.randint(0,length_labels-1)\n",
    "        label = labels[index]\n",
    "        if label == 1:\n",
    "            train_indexes.append(index)\n",
    "            trainingY.append(label)\n",
    "            counter+=1\n",
    "    trainingX = K[np.ix_(train_indexes, train_indexes)]\n",
    "\n",
    "    #train\n",
    "    clf = svm.SVC(gamma='scale')\n",
    "    clf.fit(trainingX, trainingY)\n",
    "    #test\n",
    "\n",
    "    pred = clf.predict(testX)\n",
    "    accuracy = np.sum(testY == pred)/len(testY)\n",
    "    print(accuracy)\n",
    "    acc[fold] = accuracy\n",
    "print('Mean of acc: ', sum(v for k,v in acc.items())/len(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6289082521783701\n",
      "0.5991799077396207\n",
      "0.7068170169144029\n",
      "0.7924141465914916\n",
      "0.5366478728856996\n",
      "0.7221937467965146\n",
      "0.787801127626858\n",
      "0.5658636596617119\n",
      "0.7626858021527422\n",
      "0.796514607893388\n",
      "0.7057919015889288\n",
      "0.7391081496668375\n",
      "0.8195797027165556\n",
      "0.5474115838031779\n",
      "0.6078933880061507\n",
      "0.8124038954382368\n",
      "0.8021527421834956\n",
      "0.7852383393131728\n",
      "0.8042029728344439\n",
      "0.6268580215274219\n",
      "0.690927729369554\n",
      "0.7549974372116863\n",
      "0.7770374167093798\n",
      "0.7647360328036904\n",
      "0.779600205023065\n",
      "0.8329062019477191\n",
      "0.6868272680676576\n",
      "0.4971809328549462\n",
      "0.7785750896975909\n",
      "0.8472578165043567\n",
      "0.5361353152229625\n",
      "0.5786776012301383\n",
      "0.7811378780112763\n",
      "0.7396207073295745\n",
      "0.8011276268580215\n",
      "0.5207585853408508\n",
      "0.7734495130702204\n",
      "0.7027165556125065\n",
      "0.7662737057919016\n",
      "0.7011788826242953\n",
      "0.7186058431573552\n",
      "0.7437211686314711\n",
      "0.5771399282419272\n",
      "0.7514095335725269\n",
      "0.5966171194259354\n",
      "0.7754997437211686\n",
      "0.7406458226550487\n",
      "0.8293182983085597\n",
      "0.7042542286007176\n",
      "0.8165043567401332\n",
      "0.6217324449000513\n",
      "0.8026652998462327\n",
      "0.7883136852895951\n",
      "0.7201435161455664\n",
      "0.8077908764736033\n",
      "0.7129677088672476\n",
      "0.7365453613531522\n",
      "0.6545361353152229\n",
      "0.5879036391594055\n",
      "0.7252690927729369\n",
      "0.8016401845207586\n",
      "0.8011276268580215\n",
      "0.7765248590466427\n",
      "0.5161455663762173\n",
      "0.770374167093798\n",
      "0.5407483341875962\n",
      "0.7575602255253716\n",
      "0.7626858021527422\n",
      "0.7539723218862122\n",
      "0.7929267042542286\n",
      "0.8436699128651973\n",
      "0.7626858021527422\n",
      "0.8385443362378268\n",
      "0.8267555099948745\n",
      "0.7888262429523322\n",
      "0.7893388006150692\n",
      "0.7642234751409533\n",
      "0.7391081496668375\n",
      "0.7180932854946181\n",
      "0.8175294720656073\n",
      "0.7447462839569452\n",
      "0.6678626345463865\n",
      "0.761148129164531\n",
      "0.7391081496668375\n",
      "0.7729369554074833\n",
      "0.6852895950794464\n",
      "0.7401332649923117\n",
      "0.7401332649923117\n",
      "0.5023065094823168\n",
      "0.6627370579190159\n",
      "0.717068170169144\n",
      "0.6827268067657611\n",
      "0.8293182983085597\n",
      "0.8359815479241415\n",
      "0.760635571501794\n",
      "0.7816504356740134\n",
      "0.831368528959508\n",
      "0.7744746283956945\n",
      "0.7288569964120963\n",
      "0.8421322398769862\n",
      "Mean of acc:  0.7283546899026139\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "acc = {}\n",
    "\n",
    "for fold in range(0,100):\n",
    "    #train samples\n",
    "    n_labeled = 16\n",
    "    length2 = n_labeled//2\n",
    "    trainingX=[]\n",
    "    trainingY=[]\n",
    "    for i in range(0, length2):\n",
    "        index = random.randint(0,length_X1-1)\n",
    "        trainingX.append(X1[index])\n",
    "        trainingY.append(label_X1[index])\n",
    "    for i in range(0, length2):\n",
    "        index = random.randint(0,length_X2-1)\n",
    "        trainingX.append(X2[index])\n",
    "        trainingY.append(label_X2[index])            \n",
    "    #train\n",
    "    clf = svm.SVC(gamma='scale')\n",
    "    clf.fit(trainingX, trainingY)\n",
    "    \n",
    "    pred = clf.predict(vectors)\n",
    "    accuracy = np.sum(labels == pred)/len(labels)\n",
    "    print(accuracy)\n",
    "    acc[fold] = accuracy\n",
    "print('Mean of acc: ', sum(v for k,v in acc.items())/len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "242px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
